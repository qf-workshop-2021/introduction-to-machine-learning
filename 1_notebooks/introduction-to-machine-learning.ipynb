{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/qf-workshop-2021/introduction-to-machine-learning/blob/main/1_notebooks/introduction-to-machine-learning.ipynb\">\n",
    "        <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books Reference\n",
    "\n",
    "These introductory lessons assume a basic level of statistical and mathematical knowledge. No previous knowledge of Machine Learning is assumed. For this reason I have decided to use two basic texts for the preparation of these lessons that you can consult for further details on the topics we are going to deal with.\n",
    "\n",
    "- John C. Hull, **Machine Learning in Business, An Introduction to the World of Data Science**, Amazon (2019)\n",
    "\n",
    "- Paul Wilmott}, **Machine Learning, An Applied Mathematics Introduction**, Panda Ohana Publishing (2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Words on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it is not essential to work in a colab environment (all the course notebooks are in fact designed to be able to run without problems locally on your pc), it is useful to know some basic elements of the interaction with colab. In particular, in the cells below you will find two examples for the use of external files. In the first case it is shown how to load a text file from your local PC into the google virtual machine. The second example relates to the opposite operation: let's create a simple pandas dataframe into the colab environment and export it in csv format to the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Upload a File on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path + \"carroll-alice.txt\", \"r\") as f:\n",
    "    alice = f.read()\n",
    "    \n",
    "alice[:392]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Download a File on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cars = {'Brand': ['Honda Civic','Toyota Corolla','Ford Focus','Audi A4'],\n",
    "        'Price': [22000,25000,27000,35000]\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(cars, columns= ['Brand', 'Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    # if we run in google environment first we save in virtual machine...\n",
    "    df.to_csv ('export_dataframe.csv', index = False, header=True)\n",
    "    # ...then we download to local machine\n",
    "    from google.colab import files\n",
    "    files.download(\"export_dataframe.csv\")    \n",
    "else:\n",
    "    # if we are working in local we save directly with the usual method\n",
    "    df.to_csv ('./data/export_dataframe.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Two definitions of Machine Learning are offered. [Arthur Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel) described it as: \"the field of study that gives computers the ability to learn without being explicitly programmed.\" This is an older, informal definition.\n",
    "\n",
    "Tom Mitchell provides a more modern definition: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\"\n",
    "\n",
    "Example: playing checkers.\n",
    "\n",
    "E = the experience of playing many games of checkers\n",
    "\n",
    "T = the task of playing checkers.\n",
    "\n",
    "P = the probability that the program will win the next game.\n",
    "\n",
    "\n",
    "To use machine learning effectively **you have to understand how the underlying algorithms work**. It is tempting to learn a language such as Python or R and apply various packages to your data without really understanding what the packages are doing or even how the results should be interpreted. This would be a bit like a finance specialist using the Black and Scholes model to value options without understanding where it comes from or its limitations.\n",
    "\n",
    "\n",
    "### Type of Machine Learning Models ###\n",
    "\n",
    "There are four main categories of machine learning models:\n",
    "\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n",
    "- Semi-Supervised Learning\n",
    "- Reinforcement Learning \n",
    "\n",
    "Supervised learning is concerned with using data to make predictions. We can distinguish between supervised learning models that are used to predict a variable and models that are used for classification. \n",
    "\n",
    "Unsupervised learning is concerned with recognizing patterns in data. The main object is not to forecast a particular variable, rather it is to understand the data environment better.\n",
    "\n",
    "### Jargon\n",
    "\n",
    "The data for supervised learning contains whare are referred to as **features** and **labels**. The **labels** are the values of the target that is to be predicted. The **features** are the variables from which the predictions are to be made. For example when predicting the price of a house the **features** could be the swuare meters of living space, the number of bedrooms, the number of bathrooms, the size of the garage and so on. The **label** would be the house price.\n",
    "\n",
    "The data for unsupervised learning consists of features but no labels because the model is being used to identify patterns not to forecast something.\n",
    "\n",
    "### Type of Data ###\n",
    "\n",
    "There are two types of data:\n",
    "\n",
    "- Numerical\n",
    "- Categorical\n",
    "\n",
    "Numerical data consists of numbers. Categorical data is data which can fall into a number of different categories, for example data to predict a house price might categorize driveways as asphalt, concrete, grass, etc. Categorical data must be converted to numbers for the purposes of analysis. \n",
    "\n",
    "The standard way of dealing with categorical features is to create a dummy variable for each category. The value of this variable is 1 if the feature is in the category and 0 otherwise. For example in the situation in which individuals are categorized as male or female, we could create two dummy variables. For man the first dummy variable would be 1 and the second would be 0. The opposite for women. This procedure is appropriate when there is no natural ordering between the feature values.\n",
    "\n",
    "When there is a natural ordering, we can reflect this in the numbers assigned. For example if the size of an order is classified as small, medium or large, we can replace the feature by a numerical variable where *small = 1*, *medium = 2* and *large = 3*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of a machine learning algorithm highly depends on the quality of the data fed into the model. Real-world data is often dirty containing outliers, missing values, wrong data types, irrelevant features, or non-standardized data. The presence of any of these will prevent the machine learning model to properly learn. For this reason, transforming raw data into a useful format is an essential stage in the machine learning process. One technique you will come across multiple times when pre-processing data is feature normalization.\n",
    "\n",
    "Data Normalization is a common practice in machine learning which consists of transforming numeric columns to a common scale. In machine learning, some feature values differ from others multiple times. The features with higher values will dominate the leaning process. However, it does not mean those variables are more important to predict the outcome of the model. Data normalization transforms multiscaled data to the same scale. After normalization, all variables have a similar influence on the model, improving the stability and performance of the learning algorithm.\n",
    "\n",
    "There are multiple normalization techniques in statistics. In this notebook, we will cover the most important ones:\n",
    "\n",
    "- The maximum absolute scaling\n",
    "- The min-max feature scaling\n",
    "- The z-score method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximum absolute scaling\n",
    "\n",
    "The maximum absolute scaling rescales each feature between -1 and 1 by dividing every observation by its maximum absolute value.\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old}}{\\max \\vert x_{old} \\vert}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The min-max feature scaling\n",
    "\n",
    "The min-max approach (often called normalization) rescales the feature to a fixed range of [0,1] by subtracting the minimum value of the feature and then dividing by the range:\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old}-x_{min}}{x_{max}-x_{min}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score\n",
    "\n",
    "The z-score method (often called standardization) transforms the data into a distribution with a mean of 0 and a standard deviation of 1. Each standardized value is computed by subtracting the mean of the corresponding feature and then dividing by the standard deviation.\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old} - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Unlike min-max scaling, the z-score does not rescale the feature to a fixed range. The z-score typically ranges from -3.00 to 3.00 (more than 99% of the data) if the input is normally distributed.\n",
    "\n",
    "It is important to bear in mind that z-scores are not necessarily normally distributed. They just scale the data and follow the same distribution as the original input. This transformed distribution has a mean of 0 and a standard deviation of 1 and is going to be the standard normal distribution only if the input feature follows a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions \n",
    "\n",
    "\n",
    "### Linear Cost Function \n",
    "\n",
    "In Machine Learning a cost function or loss function is used to represent how far away a mathematical model is from the real data. One adjusts the mathematical model, usually by varying parameters within the model, so as to minimize the cost function. \n",
    "\n",
    "Let's take for example the simple case of a linear fitting. We want to find a relationship of the form \n",
    "\n",
    "\\begin{equation}\n",
    "y=\\theta_0 +\\theta_1x\n",
    "\\end{equation}\n",
    "\n",
    "where the $\\theta$s are the parameters that we want to find to give us the best fit to the data. We call this linear function $h_\\theta(x)$ to emphasize the dependence on both the variable $x$ and the two parameters $\\theta_0$ and $\\theta_1$.\n",
    "\n",
    "\n",
    "We want to measure how far away the data, the $y^{(n)}$s, are from the function $h_\\theta(x)$. A common way to do this is via the quadratic *cost function*\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{\\theta}) = \\frac{1}{2N} \\sum\\limits_{n=1}^N \\left[ h_\\theta \\left( x^{(n)} \\right) - y^{(n)} \\right]^2\n",
    "\\label{eq:ols}\n",
    "\\end{equation}\n",
    "\n",
    "This is called *Ordinary Least Squares*.\n",
    "\n",
    "In this case, the minimum is easily find analitically, differentiate $\\eqref{eq:ols}$ with respect to both $\\theta$s and set the result to zero:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{lcl} \n",
    "\\frac{\\partial J}{\\partial \\theta_0} & = & \\sum\\limits_{n=1}^N \\left( \\theta_0 + \\theta_1 x^{(n)} - y^{(n)} \\right) = 0 \n",
    "\\\\ \n",
    "\\frac{\\partial J}{\\partial \\theta_1} & = & \\sum\\limits_{n=1}^N x^{(n)} \\left( \\theta_0 + \\theta_1 x^{(n)} - y^{(n)} \\right) = 0 \n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "The solution is trivially obtained for both $\\theta$s\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{lcl} \n",
    "\\theta_0 = \\frac{\\left(\\sum y \\right) \\left(\\sum x^2 \\right) -\\left(\\sum x \\right) \\left(\\sum xy \\right) }{N\\left(\\sum x^2 \\right) \\left(\\sum x \\right)^2 } \n",
    "\\\\ \n",
    "\\theta_1 = \\frac{N\\left(\\sum xy \\right) - \\left(\\sum y \\right)\\left(\\sum x \\right)}{N\\left(\\sum x^2 \\right) \\left(\\sum x \\right)^2 }\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The scheme works as follow: start with an initial guess for each parameter $\\theta_k$. Then move $\\theta_k$ in the direction of the slope:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_k^{new} =\\theta_k^{old}+\\beta \\frac{\\partial J}{\\partial \\theta_k}\n",
    "\\end{equation}\n",
    "\n",
    "**Update all $\\theta_k$ simultaneously** and repet until convergence. Here $\\beta$ is a *learning factor* that governs how far you move. if $\\beta$ is too small it will take a long time to converge, if too large it will overshoot and might not converge at all. \n",
    "\n",
    "The loss function $J$ is a function of all of the data points. In the above description of gradient descent we have used all of the data points simultaneously. This is called *batch gradient* descent. But rather than use all of the data in the parameter updating we can use a technique called *stochastic gradient descent*. This is like batch gradient descent except that you only update using *one* of the data points each time. And that data point is chosen randomly.\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{\\theta}) = \\sum\\limits_{n=1}^N J_n(\\mathbf{\\theta})\n",
    "\\end{equation}\n",
    "\n",
    "Stochastic gradient descent means pick an *n* at random and then update according to \n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_k^{new} =\\theta_k^{old}+\\beta \\frac{\\partial J_n}{\\partial \\theta_k}\n",
    "\\end{equation}\n",
    "\n",
    "Repeat, picking another data point at random, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important parameter in Gradient Descent is the size of the steps, determined by\n",
    "the learning rate hyperparameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<div>\n",
    "<img src=\"pic_50.png\" width=\"600\"/>\n",
    "</div>\n",
    "-->\n",
    "![caption](pic_50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the learning rate is too small, then the algorithm\n",
    "will have to go through many iterations to converge, which will take a long time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<div>\n",
    "<img src=\"pic_51.png\" width=\"600\"/>\n",
    "</div>\n",
    "-->\n",
    "![caption](pic_51.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... on the other hand, if the learning rate is too high, you might jump across the valley. This might make the algorithm diverge failing to find a good solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<div>\n",
    "<img src=\"pic_52.png\" width=\"600\"/>\n",
    "</div>\n",
    "-->\n",
    "![caption](pic_52.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Testing \n",
    "\n",
    "When data is used for forecasting there is a danger that the machine learning model will work very well for data, but will not generalize well to other data. An obvious point is that it is important that the data used in a machine learning model be representative of the situations to which the model is to be applied. It is also important to test a model out-of-sample, by this we mean that the model should be tested on data that is different from the sample data used to determine the parameters of the model.\n",
    "\n",
    "Data scientist refer to the sample data as the **training set** and the data used to determine the accuracy of the model as the **test set**, often a **validation set** is used as well as we explain later;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Salary\n",
      "0   25  135000\n",
      "1   27  105000\n",
      "2   30  105000\n",
      "3   35  220000\n",
      "4   40  300000\n"
     ]
    }
   ],
   "source": [
    "# Load the Pandas libraries with alias 'pd' \n",
    "import pandas as pd \n",
    "# Read data from file 'salary_vs_age_1.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, with read_table \n",
    "df1 = pd.read_table(path + \"salary_vs_age_1.csv\", sep=\";\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "ax=plt.gca()\n",
    "\n",
    "df1.plot(x ='Age', y='Salary', kind = 'scatter', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[polynomial fitting with pandas](https://joshualoong.com/2018/10/03/Fitting-Polynomial-Regressions-in-Python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1 = df1['Age']\n",
    "y1 = df1['Salary']\n",
    "\n",
    "n = len(x1)\n",
    "\n",
    "degree = 5\n",
    "\n",
    "weights = np.polyfit(x1, y1, degree)\n",
    "model   = np.poly1d(weights)\n",
    "\n",
    "xx1 = np.arange(x1[0], x1[n-1], 0.1)\n",
    "plt.plot(xx1, model(xx1))\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.scatter(x1,y1, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error:\n",
      "12902.203044361002\n"
     ]
    }
   ],
   "source": [
    "y1  = np.array(y1)\n",
    "yy1 = np.array(model(x1))\n",
    "\n",
    "rmse = np.sqrt(np.sum((y1-yy1)**2)/(n-1)) \n",
    "\n",
    "print('Root Mean Square Error:')\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error:\n",
      "38825.22050917512\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_table(path + \"salary_vs_age_2.csv\", sep=\";\") \n",
    "x2 = df2['Age']\n",
    "y2 = df2['Salary']\n",
    "n  = len(x2)\n",
    "\n",
    "y2  = np.array(y2)\n",
    "yy2 = np.array(model(x2))\n",
    "\n",
    "rmse = np.sqrt(np.sum((y2-yy2)**2)/(n-1)) \n",
    "\n",
    "print('Root Mean Square Error:')\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx2 = np.arange(x2[0], x2[n-1], 0.1)\n",
    "plt.plot(xx2, model(xx2))\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.scatter(x2,y2, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The root mean squared error (rmse) for the training      data set is \\$12,902\n",
    "- The rmse for the test data set is \\$38,794\n",
    "\n",
    "We conclude that the model overfits the data. The complexity of the model should be increased only until out-of-sample tests indicate that it does not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance\n",
    "\n",
    "Suppose there is a relationship between an independent variable $x$ and a dependent variable $y$:\n",
    "\n",
    "\\begin{equation}\n",
    "    y=f(x) + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\epsilon$ is an error term with mean zero and variance $\\sigma^2$. The error term captures either genuine randomness in the data or noise due to measurement error.\n",
    "\n",
    "Suppose we find a deterministic model for this relationship:\n",
    "\n",
    "\\begin{equation}\n",
    "    y = \\hat f(x)\n",
    "\\end{equation}\n",
    "\n",
    "Now it comes a new data point $x^\\prime$ not in the training set and we want to predict the corresponding $y^\\prime$. The error we will observe in our model at point $x^\\prime$ is going to be\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat f(x^\\prime) - f(x^\\prime) - \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "There are two different sources of error in this equation. The first one is included in the factor $\\epsilon$, the second one, more interesting, is due to what is in our training set. A robust model should give us the same prediction whatever data we used for training out model. Let's look at the average error:\n",
    "\n",
    "\\begin{equation}\n",
    "E \\left[ \\hat f (x^\\prime ) \\right] - f(x^\\prime)\n",
    "\\end{equation}\n",
    "\n",
    "where the expectation is taken over random samples of training data (having the same distributio as the training data). \n",
    "\n",
    "This is the definition of the **bias**\n",
    "\n",
    "\\begin{equation}\n",
    "    \\textrm{Bias} \\left[\\hat f (x^\\prime) \\right] = E \\left[ \\hat f (x^\\prime ) \\right] - f(x^\\prime)\n",
    "\\end{equation}\n",
    "\n",
    "We can also look at the mean square error\n",
    "\n",
    "\\begin{equation}\n",
    "E \\left[\\left( \\hat f (x^\\prime ) - f(x^\\prime) - \\epsilon \\right)^2\\right] =\n",
    "\\left[ \\textrm{Bias} \\left( \\hat f(x^\\prime) \\right) \\right]^2 + \\textrm{Var}\\left[ \\hat f(x^\\prime) \\right] + \\sigma^2\n",
    "\\end{equation}\n",
    "\n",
    "Where we remember that $\\hat f (x^\\prime)$ and $\\epsilon$ are independent.\n",
    "\n",
    "This show us that there are two important quantities, the **bias** and the **variance** that will affect our results and that we can control to some extent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIGURE 1.1 - A good model should have low bias and low variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoo3dlmRGkYb"
   },
   "source": [
    "<!--\n",
    "<div>\n",
    "<img src=\"bias_and_variance_1.png\" width=\"600\"/>\n",
    "</div>\n",
    "-->\n",
    "![caption](bias_and_variance_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias is how far away the trained model is from the correct result on average**. Where *on average* means over many goes at training the model using different data. And **Variance is a measure of the magnitude of that error**.\n",
    "\n",
    "\n",
    "Unfortunately, we often find that there is a trade-off between bias and variance. As one is reduced, the other is increased. This is the matter of over- and under-fitting.\n",
    "\n",
    "**Overfitting is when we train our algorithm too well on training data, perhaps having too many parameters for fitting**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<div>\n",
    "<img src=\"bias_and_variance_2.png\" width=\"600\"/>\n",
    "</div>\n",
    "-->\n",
    "![caption](bias_and_variance_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "### Ridge Regression \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression is a regularization technique where we change the function that is to be minimize. Reduce magnitude of regression coefficients by choosing a parameter $\\lambda$ and minimizing\n",
    "\t\t\n",
    "\\begin{equation}\n",
    "\t\t\\frac{1}{2N} \\sum\\limits_{n=1}^N \\left[h_\\theta \\left( x^{(n)} \\right) - y ^{(n)}\\right]^2\t+ \\lambda \\sum\\limits_{n=1}^N b_i^2 \\notag\n",
    "\\end{equation}\n",
    "\n",
    "This change has the effect of encouraging the model to keep the weights $b_j$ as small as possibile. The Ridge regression should only be used for determining model parameters using the training set. Once the model parameters have been determined the penalty term should be removed for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260000</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>240000</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>265000</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary  Age\n",
       "0  135000   25\n",
       "1  105000   27\n",
       "2  105000   30\n",
       "3  220000   35\n",
       "4  300000   40\n",
       "5  270000   45\n",
       "6  265000   50\n",
       "7  260000   55\n",
       "8  240000   60\n",
       "9  265000   65"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_titles = [\"Salary\",\"Age\"]\n",
    "df2=df1.reindex(columns=columns_titles)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age2</th>\n",
       "      <th>Age3</th>\n",
       "      <th>Age4</th>\n",
       "      <th>Age5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>25</td>\n",
       "      <td>625</td>\n",
       "      <td>15625</td>\n",
       "      <td>390625</td>\n",
       "      <td>9765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.0</td>\n",
       "      <td>27</td>\n",
       "      <td>729</td>\n",
       "      <td>19683</td>\n",
       "      <td>531441</td>\n",
       "      <td>14348907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.0</td>\n",
       "      <td>30</td>\n",
       "      <td>900</td>\n",
       "      <td>27000</td>\n",
       "      <td>810000</td>\n",
       "      <td>24300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1225</td>\n",
       "      <td>42875</td>\n",
       "      <td>1500625</td>\n",
       "      <td>52521875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1600</td>\n",
       "      <td>64000</td>\n",
       "      <td>2560000</td>\n",
       "      <td>102400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270.0</td>\n",
       "      <td>45</td>\n",
       "      <td>2025</td>\n",
       "      <td>91125</td>\n",
       "      <td>4100625</td>\n",
       "      <td>184528125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265.0</td>\n",
       "      <td>50</td>\n",
       "      <td>2500</td>\n",
       "      <td>125000</td>\n",
       "      <td>6250000</td>\n",
       "      <td>312500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260.0</td>\n",
       "      <td>55</td>\n",
       "      <td>3025</td>\n",
       "      <td>166375</td>\n",
       "      <td>9150625</td>\n",
       "      <td>503284375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>240.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3600</td>\n",
       "      <td>216000</td>\n",
       "      <td>12960000</td>\n",
       "      <td>777600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>265.0</td>\n",
       "      <td>65</td>\n",
       "      <td>4225</td>\n",
       "      <td>274625</td>\n",
       "      <td>17850625</td>\n",
       "      <td>1160290625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary  Age  Age2    Age3      Age4        Age5\n",
       "0   135.0   25   625   15625    390625     9765625\n",
       "1   105.0   27   729   19683    531441    14348907\n",
       "2   105.0   30   900   27000    810000    24300000\n",
       "3   220.0   35  1225   42875   1500625    52521875\n",
       "4   300.0   40  1600   64000   2560000   102400000\n",
       "5   270.0   45  2025   91125   4100625   184528125\n",
       "6   265.0   50  2500  125000   6250000   312500000\n",
       "7   260.0   55  3025  166375   9150625   503284375\n",
       "8   240.0   60  3600  216000  12960000   777600000\n",
       "9   265.0   65  4225  274625  17850625  1160290625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Salary'] = df2['Salary']/1000 \n",
    "df2['Age2']=df2['Age']**2\n",
    "df2['Age3']=df2['Age']**3\n",
    "df2['Age4']=df2['Age']**4\n",
    "df2['Age5']=df2['Age']**5\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the z-score in Pandas using the .mean() and std() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age2</th>\n",
       "      <th>Age3</th>\n",
       "      <th>Age4</th>\n",
       "      <th>Age5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.289948</td>\n",
       "      <td>-1.128109</td>\n",
       "      <td>-0.988322</td>\n",
       "      <td>-0.873562</td>\n",
       "      <td>-0.782128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.0</td>\n",
       "      <td>-1.148195</td>\n",
       "      <td>-1.045510</td>\n",
       "      <td>-0.943059</td>\n",
       "      <td>-0.849996</td>\n",
       "      <td>-0.770351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.0</td>\n",
       "      <td>-0.935566</td>\n",
       "      <td>-0.909699</td>\n",
       "      <td>-0.861444</td>\n",
       "      <td>-0.803378</td>\n",
       "      <td>-0.744782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>-0.581185</td>\n",
       "      <td>-0.651577</td>\n",
       "      <td>-0.684372</td>\n",
       "      <td>-0.687799</td>\n",
       "      <td>-0.672266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.0</td>\n",
       "      <td>-0.226804</td>\n",
       "      <td>-0.353745</td>\n",
       "      <td>-0.448740</td>\n",
       "      <td>-0.510508</td>\n",
       "      <td>-0.544103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270.0</td>\n",
       "      <td>0.127577</td>\n",
       "      <td>-0.016202</td>\n",
       "      <td>-0.146184</td>\n",
       "      <td>-0.252677</td>\n",
       "      <td>-0.333075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265.0</td>\n",
       "      <td>0.481958</td>\n",
       "      <td>0.361052</td>\n",
       "      <td>0.231663</td>\n",
       "      <td>0.107030</td>\n",
       "      <td>-0.004250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260.0</td>\n",
       "      <td>0.836340</td>\n",
       "      <td>0.778017</td>\n",
       "      <td>0.693166</td>\n",
       "      <td>0.592463</td>\n",
       "      <td>0.485972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>240.0</td>\n",
       "      <td>1.190721</td>\n",
       "      <td>1.234693</td>\n",
       "      <td>1.246690</td>\n",
       "      <td>1.229979</td>\n",
       "      <td>1.190828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>265.0</td>\n",
       "      <td>1.545102</td>\n",
       "      <td>1.731080</td>\n",
       "      <td>1.900602</td>\n",
       "      <td>2.048447</td>\n",
       "      <td>2.174155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary       Age      Age2      Age3      Age4      Age5\n",
       "0   135.0 -1.289948 -1.128109 -0.988322 -0.873562 -0.782128\n",
       "1   105.0 -1.148195 -1.045510 -0.943059 -0.849996 -0.770351\n",
       "2   105.0 -0.935566 -0.909699 -0.861444 -0.803378 -0.744782\n",
       "3   220.0 -0.581185 -0.651577 -0.684372 -0.687799 -0.672266\n",
       "4   300.0 -0.226804 -0.353745 -0.448740 -0.510508 -0.544103\n",
       "5   270.0  0.127577 -0.016202 -0.146184 -0.252677 -0.333075\n",
       "6   265.0  0.481958  0.361052  0.231663  0.107030 -0.004250\n",
       "7   260.0  0.836340  0.778017  0.693166  0.592463  0.485972\n",
       "8   240.0  1.190721  1.234693  1.246690  1.229979  1.190828\n",
       "9   265.0  1.545102  1.731080  1.900602  2.048447  2.174155"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the z-score method in Pandas using the .mean() and .std() methods\n",
    "def z_score(df):\n",
    "    # copy the dataframe\n",
    "    df_std = df.copy()\n",
    "    # apply the z-score method\n",
    "    for column in df_std.columns:\n",
    "        df_std[column] = (df_std[column] - df_std[column].mean()) / df_std[column].std()\n",
    "        \n",
    "    return df_std\n",
    "    \n",
    "# call the z_score function\n",
    "df2_standard = z_score(df2)\n",
    "df2_standard['Salary'] = df2['Salary']\n",
    "df2_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2_standard['Salary']\n",
    "X = df2_standard.drop('Salary',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -32622.57240727  135402.73116519 -215493.11781297  155314.61367273\n",
      "  -42558.76209732]\n",
      "Mean squared error: 149.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "y_pred = lr.predict(X)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', lr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(X['Age'], y,  color='black')\n",
    "plt.plot(X['Age'], y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge(alpha=0.1, normalize=True) \n",
    "# higher the alpha value, more restriction on the coefficients; low alpha > more generalization,\n",
    "# in this case linear and ridge regression resembles\n",
    "rr.fit(X, y)\n",
    "\n",
    "y_pred_r = rr.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(X['Age'], y,  color='black')\n",
    "plt.plot(X['Age'], y_pred_r, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 59.22629315  29.03476514   3.29697763 -16.42544961 -30.17329953]\n",
      "Mean squared error: 1615.07\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', rr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y, y_pred_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso is short for \\textit{Least Absolute Shrinkage and Selection Operator}. It is similar to ridge regression except we minimize\n",
    "\n",
    "\\begin{equation}\n",
    "\t\t\\frac{1}{2N} \\sum\\limits_{n=1}^N \\left[h_\\theta \\left( x^{(n)} \\right) - y ^{(n)}\\right]^2 + \\lambda \\sum\\limits_{n=1}^N \\vert b_n \\vert \\notag\n",
    "\\end{equation}\n",
    "\n",
    "This function cannot be minimized analytically and so a variation on the gradient descent algorithm must be used. Lasso regression also has the effect of simplifying the model. It does this by setting the weights of unimportant features to zero. When there are a large number of features, Lasso can identify a relatively small subset of the features that form a good predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lsr = Lasso(alpha=.02, normalize=True, max_iter=1000000) \n",
    "# higher the alpha value, more restriction on the coefficients; low alpha > more generalization,\n",
    "# in this case linear and ridge regression resembles\n",
    "lsr.fit(X, y)\n",
    "\n",
    "y_pred_lsr = rr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 344.99709034   -0.         -471.80600937   -0.          183.42041303]\n",
      "Mean squared error: 1615.07\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', lsr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y, y_pred_lsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(X['Age'], y,  color='black')\n",
    "plt.plot(X['Age'], y_pred_lsr, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle ground between Ridge and Lasso. Minimize\n",
    "\n",
    "\\begin{equation}\n",
    "\t\t\\frac{1}{2N} \\sum\\limits_{n=1}^N \\left[h_\\theta \\left( x^{(n)} \\right) - y ^{(n)}\\right]^2 + \\lambda_1 \\sum\\limits_{n=1}^N b_n^2 + \\lambda_2 \\sum\\limits_{n=1}^N \\vert b_n \\vert \\notag\n",
    "\\end{equation}\n",
    "\n",
    "In Lasso some weights are reduced to zero but others may be quite large. In Ridge, weights are small in magnitude but they are not reduced to zero. The idea underlying Elastic Net is that we may be able to get the best of both by making some weights zero while reducing the magnitude of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# define model\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning uses machine learning algorithms to analyze and cluster unlabeled datasets. These algorithms discover hidden patterns or data groupings without the need for human intervention. Its ability to discover similarities and differences in information make it the ideal solution for exploratory data analysis, cross-selling strategies, customer segmentation, and image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *k*-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*k*-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n",
    "Typically, unsupervised algorithms make inferences from datasets using only input vectors without referring to known, or labelled, outcomes. The objective of K-means is simple: group similar data points together and discover underlying patterns. To achieve this objective, K-means looks for a fixed number (k) of clusters in a dataset.\n",
    "\n",
    "A cluster refers to a collection of data points aggregated together because of certain similarities. Youll define a target number k, which refers to the number of centroids you need in the dataset. A centroid is the imaginary or real location representing the center of the cluster.\n",
    "\n",
    "Every data point is allocated to each of the clusters through reducing the in-cluster sum of squares.\n",
    "In other words, the K-means algorithm identifies k number of centroids, and then allocates every data point to the **nearest** cluster, while keeping the centroids as small as possible.\n",
    "\n",
    "The means in the K-means refers to averaging of the data; that is, finding the centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"K-means_convergence.gif\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Chire - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=59409335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the K-means algorithm works\n",
    "\n",
    "To process the learning data, the K-means algorithm in data mining starts with a first group of randomly selected centroids, which are used as the beginning points for every cluster, and then performs iterative (repetitive) calculations to optimize the positions of the centroids. It halts creating and optimizing clusters when either:\n",
    "\n",
    "- The centroids have stabilized  there is no change in their values because the clustering has been successful.\n",
    "- The defined number of iterations has been achieved.\n",
    "\n",
    "### A Distance Measure\n",
    "\n",
    "For clustering we need a distance measure. The simplest distance measure is the Euclidean Distance measure:\n",
    "\n",
    "$$\n",
    "Distance = \\sqrt{(x_B-x_B)^2 + (y_B - y_A)^2}\n",
    "$$\n",
    "\n",
    "### K-means algorithm example problem\n",
    "Lets see the steps on how the K-means machine learning algorithm works using the Python programming language.\n",
    "Well use the Scikit-learn library and some random data to illustrate a K-means clustering simple explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for generating some random data in a two-dimensional space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  =    -2 * np.random.rand(100,2)\n",
    "X1 = 1 + 2 * np.random.rand(50,2)\n",
    "X[50:100, :] = X1\n",
    "plt.scatter(X[ : , 0], X[ :, 1], s = 10, c = 'b')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This give us two sets approximately centered about (-1,-1) and (2, 2). Well use some of the available functions in the Scikit-learn library to process the randomly generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "Kmean = KMeans(n_clusters=2)\n",
    "Kmean.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we arbitrarily gave k (n_clusters) an arbitrary value of two.\n",
    "Here is the output of the K-means parameters we get if we run the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
    " n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
    " random_state=None, tol=0.0001, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmean.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[ : , 0], X[ : , 1], s =10, c='b')\n",
    "plt.scatter(-0.94665068, -0.97138368, s=100, c='g', marker='s')\n",
    "plt.scatter( 2.01559419,  2.02597093, s=100, c='r', marker='s')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for getting the labels property of the K-means clustering example dataset; that is, how the data points are categorized into the two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmean.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, 50 data points belong to the 0 cluster while the rest belong to the 1 cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, lets use the code below for predicting the cluster of a data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test=np.array([-3.0,-3.0])\n",
    "second_test=sample_test.reshape(1, -1)\n",
    "Kmean.predict(second_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Country Risk Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages \n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as clrs\n",
    "\n",
    "# Kmeans algorithm from scikit-learn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Country Risk Dataset (J. C. Hull, 2019, Chapter 2)\n",
    "\n",
    "Consider the problem of understanding the risk of countries for foreign investment. Among the features that can be used for this are:\n",
    "\n",
    "- GDP growth rate (IMF)\n",
    "- Corruption index (Transparency international)\n",
    "- Peace index (Institute for Economics and Peace)\n",
    "- Legal Risk Index (Property Rights Association)\n",
    "\n",
    "Values for each of the features for 122 countries are found in the `countryriskdata.csv` (available [here](http://www-2.rotman.utoronto.ca/~hull))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "raw = pd.read_csv(os.path.join(path, 'countryriskdata.csv'))\n",
    "\n",
    "# check the raw data\n",
    "print(\"Size of the dataset (row, col): \", raw.shape)\n",
    "print(\"\\nFirst 5 rows\\n\", raw.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GDP growth rate (%) is typically a positive or negative number with a magnitude less than 10. The corruption index is on a scale from 0 (highly corrupt) to 100 (no corruption). The peace index is on a scale from 1 (very peaceful) to 5 (not at all peaceful). The legal risk index runs from 0 to 10 (with high values being favorable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple exploratory analysis\n",
    "\n",
    "**Print summary statistics**\n",
    "\n",
    "Note that all features have quite different variances, and Corruption and Legal are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary statistics\n",
    "print(\"\\nSummary statistics\\n\", raw.describe())\n",
    "print(\"\\nCorrelation matrix\\n\", raw.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot histogram**\n",
    "\n",
    "Note that distributions for GDP Growth is quite skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms\n",
    "plt.figure(1)\n",
    "raw['Corruption'].plot(kind = 'hist', title = 'Corruption', alpha = 0.5)\n",
    "\n",
    "plt.figure(2)\n",
    "raw['Peace'].plot(kind = 'hist', title = 'Peace', alpha = 0.5)\n",
    "\n",
    "plt.figure(3)\n",
    "raw['Legal'].plot(kind = 'hist', title = 'Legal', alpha = 0.5)\n",
    "\n",
    "plt.figure(4)\n",
    "raw['GDP Growth'].plot(kind = 'hist', title = 'GDP Growth', alpha = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means cluster\n",
    "\n",
    "**Pick features & normalization**\n",
    "\n",
    "Since Corruption and Legal are highly correlated, we drop the Corruption variable, i.e., we pick three features for this analysis, Peace, Legal and GDP Grwoth. Let's normalize all the features, effectively making them equally weighted.\n",
    "\n",
    "Ref. [Feature normalization.](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = raw[['Peace', 'Legal', 'GDP Growth']]\n",
    "X = (X - X.mean()) / X.std()\n",
    "print(X.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform elbow method\n",
    "\n",
    "In cluster analysis, the elbow method is a heuristic used in determining the number of clusters in a data set. The method consists of plotting the explained variation as a function of the number of clusters, and picking the elbow of the curve as the number of clusters to use. The same method can be used to choose the number of parameters in other data-driven models, such as the number of principal components to describe a data set.\n",
    "\n",
    "For example in the following picture k=4 is suggested\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"pic_13_C.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "In our case, the marginal gain of adding one cluster dropped quite a bit from k=3 to k=4. We will choose k=3 (not a clear cut though).\n",
    "\n",
    "Ref. [Determining the number of clusters in a dataset.](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41540751/sklearn-kmeans-equivalent-of-elbow-method\n",
    "\n",
    "Ks = range(1, 10)\n",
    "inertia = [KMeans(i).fit(X).inertia_ for i in Ks]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(Ks, inertia, '-bo')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia (within-cluster sum of squares)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***k*-means with k=3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# print inertia & cluster center\n",
    "print(\"inertia for k=2 is\", kmeans.inertia_)\n",
    "print(\"cluster centers: \", kmeans.cluster_centers_)\n",
    "\n",
    "# take a quick look at the result\n",
    "y = kmeans.labels_\n",
    "print(\"cluster labels: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the result (3D plot)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the color\n",
    "norm = clrs.Normalize(vmin=0.,vmax=y.max())\n",
    "cmap = cm.viridis\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X.iloc[:,0], X.iloc[:,1], X.iloc[:,2], c=cmap(norm(y)), marker='o')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "ax.scatter(centers[:, 0], centers[:, 1], c='red', s=100, alpha=0.5, marker='o')\n",
    "\n",
    "ax.set_xlabel('Peace')\n",
    "ax.set_ylabel('Legal')\n",
    "ax.set_zlabel('GDP Growth')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the result (3 2D plots)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figs = [(0, 1), (0, 2), (1, 2)]\n",
    "labels = ['Peace', 'Legal', 'GDP Growth']\n",
    "\n",
    "for i in range(3):\n",
    "    fig = plt.figure(i)\n",
    "    plt.scatter(X.iloc[:,figs[i][0]], X.iloc[:,figs[i][1]], c=cmap(norm(y)), s=50)\n",
    "    plt.scatter(centers[:, figs[i][0]], centers[:, figs[i][1]], c='black', s=200, alpha=0.5)\n",
    "    plt.xlabel(labels[figs[i][0]])\n",
    "    plt.ylabel(labels[figs[i][1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the result (3 2D plots)**\n",
    "\n",
    "plot country abbreviations instead of dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figs = [(0, 1), (0, 2), (1, 2)]\n",
    "labels = ['Peace', 'Legal', 'GDP Growth']\n",
    "colors = ['blue','green', 'red']\n",
    "\n",
    "for i in range(3):\n",
    "    fig = plt.figure(i, figsize=(8, 8))\n",
    "    x_1 = figs[i][0]\n",
    "    x_2 = figs[i][1]\n",
    "    plt.scatter(X.iloc[:, x_1], X.iloc[:, x_2], c=y, s=0, alpha=0)\n",
    "    plt.scatter(centers[:, x_1], centers[:, x_2], c='black', s=200, alpha=0.5)\n",
    "    for j in range(X.shape[0]):\n",
    "        plt.text(X.iloc[j, x_1], X.iloc[j, x_2], raw['Abbrev'].iloc[j], \n",
    "                 color=colors[y[j]], weight='semibold', horizontalalignment = 'center', verticalalignment = 'center')\n",
    "    plt.xlabel(labels[x_1])\n",
    "    plt.ylabel(labels[x_2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Country':raw['Country'], 'Abbrev':raw['Abbrev'], 'Label':y})\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "    print(result.sort_values('Label'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each observation $i$ calculate $a(i)$, the average distance from other observations in its cluster, and $b(i)$, the average distance from observations in the closest other cluster. The silhouette score for observation $i$, $s(i)$, is defined as \n",
    "\t\t\\begin{equation}\n",
    "\t\ts(i) = \\frac{b(i)-a(i)}{\\max[a(i),b(i)]}\n",
    "\\end{equation}\t\t   \n",
    "\n",
    "Choose the number of clusters that maximizes the average silhouette score across all observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Analysis\n",
    "range_n_clusters = [2,3,4,5,6,7,8,9,10]\n",
    "silhouette       = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    clusterer=KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    cluster_labels=clusterer.fit_predict(X)\n",
    "    silhouette_avg=silhouette_score(X,cluster_labels)\n",
    "    silhouette.append(silhouette_avg)\n",
    "    #print(\"For n_clusters=\", n_clusters,\n",
    "    #      \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range_n_clusters, silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model makes a prediction by simply computing a weighted\n",
    "sum of the input features, plus a constant called the *bias* term (also called the *intercept*\n",
    "term):\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\hat y$ is the predicted value;\n",
    "- $n$ is the number of features;\n",
    "- $x_i$ is the $i^{th}$ feature value;\n",
    "- $\\theta_j$ is the $j^{th}$ model parameter (including the bias term $\\theta_0$ and the feature weights $\\theta_1, \\theta_2, \\dots, \\theta_n$\n",
    "\n",
    "Training a model means setting its parameters so that the model best fits the training set. For this purpose, we first need a measure of how well (or poorly) the model fits the training data. The most common performance measure of a regression model is the Root Mean Square Error (RMSE), therefore, to train a Linear Regression model, you need to find the value of  that minimizes the RMSE. In practice, it is simpler to minimize the Mean Square Error (MSE) than the RMSE, and it leads to the same result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Practical Example from Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "The objective is to predict the prices of house in Iowa from features. We have 800 observations in training set, 600 in validation set, and 508 in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "\n",
    "Categorical features are features where there are a number of non-numerical alternatives. We can define a dummy variable for each alternative. The variable equals 1 if the alternative is true and zero otherwise. This is known as **one-hot encoding**.\n",
    "But sometimes we do not have to do this because there is a natural ordering of variables. For example in this problem one of the categorical features is concerned with the basement quality as indicated by the ceiling height. The categories are:\n",
    "\n",
    "- *Excellent (< 100 inches)*\n",
    "- *Good (90-99 inches)*\n",
    "- *Typical (80-89 inches)*\n",
    "- *Fair (70-79 inches)*\n",
    "- *Poor (< 70 inches)*\n",
    "- *No Basement*\n",
    "\n",
    "This is an example of a categorical variable where *there is* a natural ordering. We created a new variable that had a values of 5, 4, 3, 2, 1 and 0 for the above six categories respectively.\n",
    "\n",
    "The other categorical features specifies the location of the house as in one of 25 neighborhoods. We introduce 25 dummy variables with a one-hot encoding. The dummy variable equals one for an observation if the neighborhood is that in which the house is located and zero otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data (J. C. Hull, 2019, Chapter 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the regression techniques discussed in this chapter we will use a total of 48 feature. 21 are numerical and two are categorical and to this we had, as discussed above, 25 categorical variables for the neighborhoods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both features and target have already been scaled: mean = 0; SD = 1\n",
    "data = pd.read_csv(path + 'Houseprice_data_scaled.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all check how many records we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of available data = \"  + str(len(data.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting we emphasize the need to divide all available data into three parts: a **training set**, a **validation set** and a **test set**. The training set is used to determine parameters for trial models. The validation set is used to determine the extent to chich the models created from the training set generalize to new data. Finally, the test set is used as a final estimate of the accuracy of the chosen model. \n",
    "\n",
    "We had 2908 observations. We split this as follows: 1800 in the training set, 600 in the validation set and 508 in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 1800 data items are training set; the next 600 are the validation set\n",
    "train = data.iloc[:1800] \n",
    "val = data.iloc[1800:2400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now procede to create **labels** and **features**. As we have already said, the labels are the values of the target that is to be predicted, in this case the 'Sale Price', and we indicate that whit 'y':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val = train[['Sale Price']], val[['Sale Price']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and dummy variables were scaled using the Z-score method. Also the target values (i.e. the house prices) have been scaled with the Z-score method. The features are the variables from which the predictions are to be made and, in this case, can be obtained simply dropping the column 'Sale Price' from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train.drop('Sale Price', axis=1), val.drop('Sale Price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataFrame with corresponding feature and its respective coefficients\n",
    "coeffs = pd.DataFrame(\n",
    "    [\n",
    "        ['intercept'] + list(X_train.columns),\n",
    "        list(lr.intercept_) + list(lr.coef_[0])\n",
    "    ]\n",
    ").transpose().set_index(0)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coeffs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_t=lr.predict(X_train)\n",
    "mse(y_train,pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_v=lr.predict(X_val)\n",
    "mse(y_val,pred_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data we are considering it turns out that this regression model generalizes well. The mean squared error for the validation set was only a little higher than that for the training set. However linear regression with no regularization leads to some strange results because of the correlation between features. For example it makes no sense that the weights for number of full bathrooms and number of bedrooms are negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = X_train['GrLivArea']\n",
    "x2 = X_train['BedroomAbvGr']\n",
    "x1.corr(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Ridge\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try using Ridge regression with different values of the hyperparameter $\\lambda$. The following code shows the effect of this parameter on the prediction error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The alpha used by Python's ridge should be the lambda in Hull's book times the number of observations\n",
    "alphas=[0.01*1800, 0.02*1800, 0.03*1800, 0.04*1800, 0.05*1800, 0.075*1800,0.1*1800,0.2*1800, 0.4*1800]\n",
    "mses=[]\n",
    "for alpha in alphas:\n",
    "    ridge=Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train,y_train)\n",
    "    pred=ridge.predict(X_val)\n",
    "    mses.append(mse(y_val,pred))\n",
    "    print(mse(y_val,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the prediction error increases as $\\lambda$ increases. Values of $\\lambda$ in the range $0$ to $0.1$ might be reasonably be considered because prediction errors increases only slightly when $\\lambda$ is in this range. However it turns out that the improvement in the model is quite small for these values of $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we produce results for alpha=0.05 which corresponds to lambda=0.1 in Hull's book\n",
    "lasso = Lasso(alpha=0.05)\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with corresponding feature and its respective coefficients\n",
    "coeffs = pd.DataFrame(\n",
    "    [\n",
    "        ['intercept'] + list(X_train.columns),\n",
    "        list(lasso.intercept_) + list(lasso.coef_)\n",
    "    ]\n",
    ").transpose().set_index(0)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso with different levels of alpha and its mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now consider different lambda values. The alphas are half the lambdas\n",
    "alphas=[0.01/2, 0.02/2, 0.03/2, 0.04/2, 0.05/2, 0.06/2, 0.08/2, 0.09/2, 0.1/2]\n",
    "mses=[]\n",
    "for alpha in alphas:\n",
    "    lasso=Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train,y_train)\n",
    "    pred=lasso.predict(X_val)\n",
    "    mses.append(mse(y_val,pred))\n",
    "    print(\"lambda = \" + '{:<05}'.format(alpha) + \" - mse = \" + str(round(mse(y_val, pred),6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression leads to more interesting results. In the plot above you can see how the error in the validation set changes as tha value of the lasso $\\lambda$ increases. For small values of $\\lambda$ the error is actually less than when $\\lambda = 0$ but as $\\lambda$ increases beyond about $0.03$ the error starts to increase. A value of $\\lambda = 0.04$ could be chosen.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John C. Hull, **Machine Learning in Business: An Introduction to the World of Data Science**, Amazon, 2019.\n",
    "\n",
    "Paul Wilmott, **Machine Learning: An Applied Mathematics Introduction**, Panda Ohana Publishing, 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
